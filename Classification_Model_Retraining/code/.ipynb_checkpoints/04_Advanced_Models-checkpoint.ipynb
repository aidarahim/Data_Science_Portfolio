{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Random Forest, Extremely Randomized Trees, Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, the subreddit posts are tokenized and Random Forest, ExtraTrees, and Support Vector Classifier models are built to predict the origin of each post, using training and testing sets, and also including cross-validation. Model performance is compared against the best logistic regression model. It is not optimized but instead the TfidfVectorizer is constrained to use the same parameters as model 1 that was created through LogisticRegression. The model is considered successful if it performs better than the best Logistic Regression model.\n",
    "\n",
    "The best model (SVC, at 85.4% testing accuracy) is then fit to the entire dataset, and pickled for use on posts scraped from 17 subsequent months. In other words, these 2000 posts are treated as the training set and posts from the other 17 subsequent months are treated as the test sets (in the next notebook). \n",
    "\n",
    "A summary of the observations is listed at the end.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "1. Generate models\n",
    "\n",
    "    1.1 Random Forest\n",
    "    \n",
    "    1.2 Extremely Randomized Trees\n",
    "    \n",
    "    1.3 Support Vector Classifier\n",
    "\n",
    "2. Rebuild SVC Model\n",
    "\n",
    "3. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC # support vector classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# this setting widens how many characters pandas will display in a column:\n",
    "pd.options.display.max_colwidth = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model based just on 'title' - there are lots of words in 'title', and some 'selftext' is empty\n",
    "X = df['title']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing sets\n",
    "# Choose not to explicitly stratify on y since dataset is pretty evenly split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of tuples tells the pipeline what order to execute the different things in\n",
    "# use tfidf, Random Forest\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# \n",
    "pipe_params = {\n",
    "    'tf__stop_words': [['lpt']], # use tf because above, we used tf for CountVectorizer\n",
    "    'tf__min_df': [2],\n",
    "    'rfc__n_estimators': [200, 500, 1000],\n",
    "    'rfc__max_depth': [10] # constrain max_depth else it would select None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing? An estimator to be optimized\n",
    "                  pipe_params, # parameter values we are searching over\n",
    "                  cv = 7) # try 7--fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('rfc', RandomForestClassifier())]),\n",
       "             param_grid={'rfc__max_depth': [10],\n",
       "                         'rfc__n_estimators': [200, 500, 1000],\n",
       "                         'tf__min_df': [2], 'tf__stop_words': [['lpt']]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch now has the pipeline\n",
    "# Fit GridSearch to training data.\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 10,\n",
       " 'rfc__n_estimators': 200,\n",
       " 'tf__min_df': 2,\n",
       " 'tf__stop_words': ['lpt']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it told us what's best\n",
    "# What's the best score?\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8740690589031821, 0.8052738336713996)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "# Score model on testing set.\n",
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was basically perfect (99% accuracy) when running the training set with unlimited max_depth. So I constrained max_depth to 10. This way, it is not grossly overfit, and performs not too differently compared to the selected LogisticRegression model (test score 85.2%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfidf, ExtraTrees\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('etc', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "# \n",
    "pipe_params = {\n",
    "    'tf__stop_words': [['lpt']], # use tf because above, we used tf for CountVectorizer\n",
    "    'tf__min_df': [2],\n",
    "    'etc__n_estimators': [200, 500, 1000],\n",
    "    'etc__max_depth': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing? An estimator to be optimized\n",
    "                  pipe_params, # parameter values we are searching over\n",
    "                  cv = 7) # try 7--fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('etc', ExtraTreesClassifier())]),\n",
       "             param_grid={'etc__max_depth': [10],\n",
       "                         'etc__n_estimators': [200, 500, 1000],\n",
       "                         'tf__min_df': [2], 'tf__stop_words': [['lpt']]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch now has the pipeline\n",
    "# Fit GridSearch to training data.\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'etc__max_depth': 10,\n",
       " 'etc__n_estimators': 500,\n",
       " 'tf__min_df': 2,\n",
       " 'tf__stop_words': ['lpt']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the best score?\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9052132701421801, 0.8174442190669371)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "# Score model on testing set.\n",
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs very similarly to its friend, the RandomForest above. The testing accuracy is higher but the degree of bias/variance tradeoff is the same (8% lower testing accuracy compared to training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfidf, Support Vector Classifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "# \n",
    "pipe_params = {\n",
    "    'tf__stop_words': [['lpt']], # use tf because above, we used tf for CountVectorizer\n",
    "    'tf__min_df': [2],\n",
    "    'svc__C': np.linspace(0, 5, 20),\n",
    "    'svc__kernel':['rbf','polynomial'],\n",
    "    'svc__degree':list(range(4))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing? An estimator to be optimized\n",
    "                  pipe_params, # parameter values we are searching over\n",
    "                  n_jobs = 4, \n",
    "                  cv = 7) # try 7--fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('svc', SVC())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'svc__C': array([0.        , 0.26315789, 0.52631579, 0.78947368, 1.05263158,\n",
       "       1.31578947, 1.57894737, 1.84210526, 2.10526316, 2.36842105,\n",
       "       2.63157895, 2.89473684, 3.15789474, 3.42105263, 3.68421053,\n",
       "       3.94736842, 4.21052632, 4.47368421, 4.73684211, 5.        ]),\n",
       "                         'svc__degree': [0, 1, 2, 3],\n",
       "                         'svc__kernel': ['rbf', 'polynomial'],\n",
       "                         'tf__min_df': [2], 'tf__stop_words': [['lpt']]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch now has the pipeline\n",
    "# Fit GridSearch to training data.\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1.0526315789473684,\n",
       " 'svc__degree': 0,\n",
       " 'svc__kernel': 'rbf',\n",
       " 'tf__min_df': 2,\n",
       " 'tf__stop_words': ['lpt']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it told us what's best\n",
    "# What's the best score?\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.991198375084631, 0.8539553752535497)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "# Score model on testing set.\n",
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training score is basically perfect on the SVC, and the testing score is higher than Random Forest and ExtraTrees. Use this model on subsequent test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rebuild SVC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild the model with the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923857868020305"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(min_df=2, stop_words = ['lpt'])),\n",
    "    ('svc', SVC(C=1.0526315789473684, degree=0, kernel='rbf'))\n",
    "])\n",
    "\n",
    "pipe.fit(X,y)\n",
    "pipe.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "* 3 additional models were evaluated. The Random Forest model was basically perfect (99% accuracy) when running the training set with unlimited max_depth. So I constrained max_depth to 10 (similarly for ExtraTrees). This way, it is not grossly overfit, and performs not too differently compared to the selected LogisticRegression model (test score 85.2%).\n",
    "\n",
    "| Model | Transformer |   Estimator  |            Details           | Accuracy (train) | Accuracy (train) |\n",
    "|:-----:|:-----------:|:------------:|:----------------------------:|:----------------:|:----------------:|\n",
    "|   1   |  TfidfVect  | RandomForest | GridSearchCV, 'lpt' stopword |       0.881      |       0.809      |\n",
    "|   2   |  TfidfVect  |  ExtraTrees  | GridSearchCV, 'lpt' stopword |       0.903      |       0.822      |\n",
    "|   3   |   TfidVect  |      SVC     | GridSearchCV, 'lpt' stopword |       0.991      |       0.854      |\n",
    "\n",
    "* With 99% training accuracy and 85.4% testing accuracy, the SVC was selected for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the optimal model for use with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/subreddit_model_svc.pkl', mode='wb') as pickle_out:\n",
    "    pickle.dump(pipe, pickle_out) # first write pipe, then the open file itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
